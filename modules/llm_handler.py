from __future__ import annotations

import logging
import os
import time
import re
from pathlib import Path
from typing import Any, Dict, Optional

from openai import OpenAI


class LLMHandler:
    """å°è£… LLM è°ƒç”¨ä¸Žæ¨¡æ¿é€‰æ‹©ã€é‡è¯•é€»è¾‘ã€‚"""

    def __init__(self, config) -> None:  # ConfigManager å®žä¾‹
        self.config = config
        # OpenAI v1 å®¢æˆ·ç«¯ï¼ˆå…è®¸è‡ªå®šä¹‰ base_url ä¸Ž api_keyï¼‰
        self.client = OpenAI(
            base_url=self.config.llm_api_base,
            api_key=self.config.llm_api_token or os.getenv("OPENAI_API_KEY", ""),
        )
        self.logger = logging.getLogger("audionote")

    def _read_text_file(self, path: str) -> Optional[str]:
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            return None

    def _select_template(self, course_name: str) -> Dict[str, str]:
        clinical_courses = [c.strip() for c in self.config.clinical_courses if c.strip()]
        name_norm = (course_name or "").strip()
        is_clinical = any(
            c == name_norm or (c and (c in name_norm or name_norm in c))
            for c in clinical_courses
        )

        clinical_path = self.config.prompt_clinical_path
        general_path = self.config.prompt_general_path

        template_name = "clinical" if is_clinical else "general"
        template_path = clinical_path if is_clinical else general_path

        content = self._read_text_file(template_path)
        if not content:
            # å›žé€€åˆ°é€šç”¨æ¨¡æ¿
            if template_path != general_path:
                content = self._read_text_file(general_path)
                template_name = "general(fallback)"
                template_path = general_path
        if not content:
            # æœ€åŽå…œåº•ï¼Œç»™ä¸€ä¸ªæœ€ç®€æŒ‡ä»¤
            content = "ä½ æ˜¯èµ„æ·±æ•™å­¦åŠ©ç†ï¼Œè¯·å°†ç»™å®šè½¬å½•æ•´ç†ä¸ºç»“æž„åŒ– Obsidian ç¬”è®°ã€‚"
            template_name = "builtin-minimal"

        self.logger.debug("[DEBUG] Selected LLM template: '%s'", template_name)
        return {"name": template_name, "path": template_path, "content": content}

    def _post_process_note(self, content: str) -> str:
        # ç»Ÿä¸€åˆ†å‰²çº¿
        s = content.replace("***", "---")
        # ä¿®å¤ Anki æ‹¬å·ä¸Žåºå·ï¼š{cN::...} -> {{c1::...}}
        s = re.sub(r"\{c\d+::(.*?)\}", r"{{c1::\1}}", s)
        # æ¸…ç†â€œä¸€å¥è¯æ€»ç»“â€æ ‡é¢˜è¡Œï¼ˆä¿ç•™æ­£æ–‡ï¼‰
        s = re.sub(r"(?mi)^\s*###\s*\d*\.?\s*(One-Sentence Summary|ä¸€å¥è¯æ€»ç»“)\s*\n", "", s)
        # åŽ»é™¤ Anki æ®µè½ä¸­çš„åˆ—è¡¨å‰ç¼€
        lines = s.splitlines()
        out_lines = []
        in_anki = False
        for line in lines:
            if re.match(r"^\s*##\s*ðŸ§ \s*Anki\s*å¡ç‰‡\s*$", line) or re.match(r"^\s*##\s*Anki\s*å¡ç‰‡\s*$", line):
                in_anki = True
                out_lines.append(line)
                continue
            if in_anki:
                if re.match(r"^\s*##\s+", line):
                    in_anki = False
                    out_lines.append(line)
                    continue
                out_lines.append(re.sub(r"^\s*-\s+", "", line))
            else:
                out_lines.append(line)
        return "\n".join(out_lines)

    def _render_prompt(self, template_text: str, transcript: str, course_info: Dict[str, Any], meta: Dict[str, Any]) -> str:
        # æŒ‰æ¨¡æ¿æ ¼å¼åŒ–ï¼šä¿æŒå·²å¡«å­—æ®µä¸å˜ï¼Œä»…è®© LLM å¡« [FILL_HERE] çš„å­—æ®µ
        fmt = {
            "course_name": course_info.get("course_name", ""),
            "week_num": course_info.get("week_num", ""),
            "date": meta.get("date", ""),
            "sequence": meta.get("sequence", ""),
            "transcript_filename": meta.get("transcript_filename", ""),
            "transcript_text": transcript,
        }
        try:
            rendered = template_text.format(**fmt)
        except Exception:
            # è‹¥æ¨¡æ¿å˜é‡ä¸åŒ¹é…ï¼Œé€€åŒ–ä¸ºç®€å•æ‹¼æŽ¥ï¼Œé¿å…ä¸­æ–­
            rendered = (
                f"{template_text}\n\n"
                f"[METADATA_FOR_CONTEXT_ONLY]\n"
                f"Course Name: {fmt['course_name']}\nDate: {fmt['date']}\nWeek: {fmt['week_num']}\n"
                f"Sequence: {fmt['sequence']}\nTranscript File Name: {fmt['transcript_filename']}\n\n"
                f"[TRANSCRIPT]\n{fmt['transcript_text']}\n"
            )
        return rendered

    def generate_note(self, transcript: str, course_info: Dict[str, Any], meta: Dict[str, Any]) -> Optional[str]:
        system_prompt = self._read_text_file(self.config.prompt_system_path) or "You are a helpful assistant."
        template = self._select_template(course_info.get("course_name", ""))
        user_prompt = self._render_prompt(template["content"], transcript, course_info, meta)

        retries = max(1, int(self.config.llm_retry_count))
        delay = max(1, int(self.config.llm_retry_delay))
        self.logger.debug("[DEBUG] Using model=%s max_tokens=%s retries=%s delay=%s",
                          self.config.llm_model_name, self.config.llm_max_tokens, retries, delay)

        for attempt in range(1, retries + 1):
            try:
                resp = self.client.chat.completions.create(
                    model=self.config.llm_model_name,
                    temperature=0.2,
                    max_tokens=self.config.llm_max_tokens,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                )
                content = (resp.choices[0].message.content or "").strip()
                if content:
                    content = self._post_process_note(content)
                if content:
                    return content
                self.logger.warning("[WARN] LLM returned empty content. attempt=%d", attempt)
            except Exception as e:
                self.logger.error("[ERROR] LLM call failed (attempt %d/%d): %s", attempt, retries, e)
            if attempt < retries:
                time.sleep(delay)

        return None


